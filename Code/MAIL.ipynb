{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7957692,"sourceType":"datasetVersion","datasetId":4680816},{"sourceId":10653461,"sourceType":"datasetVersion","datasetId":6597049},{"sourceId":13343393,"sourceType":"datasetVersion","datasetId":8461487}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\nsns.set_style('whitegrid')\nfrom sklearn.metrics import confusion_matrix , classification_report\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense , Flatten , Conv2D , MaxPooling2D , Dropout , Activation , BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam , Adamax\nfrom tensorflow.keras import regularizers\n\n#Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n#tf.keras.mixed_precision.set_global_policy('mixed_float16')\n\nimport tensorflow as tf\nimport numpy as np\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import KLDivergence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet121, ResNet50V2\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport copy\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, BatchNormalization, ReLU, Add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.losses import KLDivergence\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications import DenseNet169, MobileNetV2, ResNet50, EfficientNetB0\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nimport copy\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modality 1","metadata":{}},{"cell_type":"code","source":"X_train_h = np.load('x_train.npy')\ny_train_h = np.load('y_train.npy')\nX_test_h = np.load('x_test(1).npy')\ny_test_h = np.load('y_test(1).npy')\n\nX_val_h = np.load('x_val.npy')\ny_val_h = np.load('y_val.npy')\n\n\nX_train_h.shape, y_train_h.shape, X_test_h.shape, y_test_h.shape, X_val_h.shape, y_val_h.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_indices = np.random.choice(1001, 810, replace=False)\n\nX_test_h1 = X_test_h[random_indices]\ny_test_h1 = y_test_h[random_indices]\n\nX_test_h1.shape, y_test_h1.shape, X_test_h.shape, y_test_h.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_indices = np.random.choice(1002, 648, replace=False)\n\nX_val_h1 = X_val_h[random_indices]\ny_val_h1 = y_val_h[random_indices]\n\nX_test_h1.shape, y_test_h1.shape, X_test_h.shape, y_test_h.shape, X_val_h1.shape, y_val_h1.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_h.shape, y_train_h.shape, X_test_h.shape, y_test_h.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Modality 2","metadata":{}},{"cell_type":"code","source":"X_train_s = np.load('X.npy')\ny_train_s = np.load('Y.npy')\n\nX_train_s.shape, y_train_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_train_s, y_train_s, test_size=0.2, random_state=42)\nX_train_s, X_val_s, y_train_s, y_val_s = train_test_split(X_train_s, y_train_s, test_size=0.2, random_state=42)\n\nX_train_s.shape,X_test_s.shape, y_train_s.shape,y_test_s.shape, y_val_s.shape,y_val_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\n\ndef rotate_image(image, angle):\n    \"\"\"\n    Rotate the image by the specified angle.\n    \"\"\"\n    center = tuple(np.array(image.shape[1::-1]) / 2)\n    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)\n    rotated_image = cv2.warpAffine(image, rotation_matrix, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n    return rotated_image\n\ndef translate_image(image, tx, ty):\n    \"\"\"\n    Translate the image by the specified translation parameters.\n    \"\"\"\n    translation_matrix = np.float32([[1, 0, tx], [0, 1, ty]])\n    translated_image = cv2.warpAffine(image, translation_matrix, image.shape[1::-1])\n    return translated_image\n\ndef apply_gaussian_blur(image, kernel_size=3):\n    \"\"\"\n    Apply Gaussian Blur to the image to reduce noise and improve generalization.\n    \"\"\"\n    blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n    return blurred_image\n\n# Augmentation parameters\nrotation_angles = [20]\ntranslations = [(5, 5)]\nkernel_sizes = [3]  # Gaussian Blur kernel sizes\n\naugmented_X_train = []\naugmented_y_train = []\n\nfor image, label in zip(X_train_s, y_train_s):\n    # Augment with rotations\n    for angle in rotation_angles:\n        rotated_image = rotate_image(image, angle)\n        augmented_X_train.append(rotated_image)\n        augmented_y_train.append(label)\n\n    # Augment with translations\n    for tx, ty in translations:\n        translated_image = translate_image(image, tx, ty)\n        augmented_X_train.append(translated_image)\n        augmented_y_train.append(label)\n\n    # Augment with Gaussian Blur\n    for kernel_size in kernel_sizes:\n        blurred_image = apply_gaussian_blur(image, kernel_size)\n        augmented_X_train.append(blurred_image)\n        augmented_y_train.append(label)\n\n# Convert lists to numpy arrays\naugmented_X_train = np.array(augmented_X_train)\naugmented_y_train = np.array(augmented_y_train)\n\n# Shuffle the data\nshuffle_indices = np.random.permutation(len(augmented_X_train))\naugmented_X_train = augmented_X_train[shuffle_indices]\naugmented_y_train = augmented_y_train[shuffle_indices]\naugmented_X_train.shape, augmented_y_train.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"random_indices = np.random.choice(7773, 5421, replace=False)\n\naugmented_X_train = augmented_X_train[random_indices]\naugmented_y_train = augmented_y_train[random_indices]\n\naugmented_X_train.shape, augmented_y_train.shape\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_s = np.concatenate((X_train_s, augmented_X_train), axis=0)\ny_train_s = np.concatenate((y_train_s, augmented_y_train), axis=0)\nX_train_s.shape, y_train_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_train_s.shape, y_train_s.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\n\ndef multi_kernel_groupwise_conv2(x, filters, groups=16, strides=1):\n    # 1x1 Group-wise Convolution\n    conv1x1 = layers.DepthwiseConv2D(kernel_size=1, strides=strides, padding=\"same\")(x)\n\n    # 3x3 Group-wise Convolution\n    conv3x3 = layers.DepthwiseConv2D(kernel_size=5, strides=strides, padding=\"same\")(x)\n\n    # 5x5 Group-wise Convolution\n    conv5x5 = layers.DepthwiseConv2D(kernel_size=7, strides=strides, padding=\"same\")(x)\n\n    # Depthwise 3x3 Group-wise Convolution\n    #depthwise3x3 = layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x)\n    \n    # Concatenate all outputs along the channel axis\n    x1 = layers.Concatenate()([conv1x1, conv3x3, conv5x5])\n    x1 = layers.Conv2D(filters, kernel_size=1, groups=groups, padding=\"same\")(x1)\n\n    x = layers.Conv2D(filters=filters, kernel_size=(1, 1), strides=strides, padding='same')(x)\n    x = layers.Add()([x, x1])\n    x = layers.Activation('relu')(x)\n    \n    return x\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nclass MultiKernelGroupwiseConv2(layers.Layer):\n    def __init__(self, filters, groups=16, strides=1, **kwargs):\n        super(MultiKernelGroupwiseConv2, self).__init__(**kwargs)\n        self.filters = filters\n        self.groups = groups\n        self.strides = strides\n\n        # 1x1 Group-wise Convolution\n        self.conv1x1 = layers.DepthwiseConv2D(kernel_size=1, strides=strides, padding=\"same\")\n\n        # 3x3 Group-wise Convolution\n        self.conv3x3 = layers.DepthwiseConv2D(kernel_size=5, strides=strides, padding=\"same\")\n\n        # 5x5 Group-wise Convolution\n        self.conv5x5 = layers.DepthwiseConv2D(kernel_size=7, strides=strides, padding=\"same\")\n\n        # Final 1x1 Group-wise Convolution\n        self.final_conv = layers.Conv2D(filters, kernel_size=1, groups=groups, padding=\"same\")\n\n        # Shortcut Path\n        self.shortcut_conv = layers.Conv2D(filters=filters, kernel_size=(1, 1), strides=strides, padding='same')\n\n        # Activation Function\n        self.activation = layers.Activation('relu')\n\n    def call(self, inputs):\n        conv1x1 = self.conv1x1(inputs)\n        conv3x3 = self.conv3x3(inputs)\n        conv5x5 = self.conv5x5(inputs)\n\n        # Concatenate along the channel axis\n        x1 = layers.Concatenate()([conv1x1, conv3x3, conv5x5])\n        x1 = self.final_conv(x1)\n\n        # Shortcut connection\n        x = self.shortcut_conv(inputs)\n        x = layers.Add()([x, x1])\n        x = self.activation(x)\n\n        return x\n\n\n# Custom Attention Block with Global Pooling\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\nclass GlobalMinPooling2D(layers.Layer):\n    def __init__(self, **kwargs):\n        super(GlobalMinPooling2D, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        return tf.reduce_min(inputs, axis=[1, 2])\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[-1])\n\n    def get_config(self):\n        config = super(GlobalMinPooling2D, self).get_config()\n        return config\n\n\n\n\n# Residual Attention Block (Using Spatial Attention)\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\ndef multi_kernel_groupwise_conv1(x, filters, groups=8, strides=2):\n    \"\"\" Advanced Multi-Kernel Groupwise Convolution Block (Without Attention, Optimized) \"\"\"\n\n    # Multi-Kernel Parallel Convolutions with Different Receptive Fields\n    conv1x1 = layers.Conv2D(filters // 4, kernel_size=1, padding=\"same\")(x)\n    conv3x3 = layers.DepthwiseConv2D(kernel_size=3, padding=\"same\")(x)\n    conv5x5 = layers.DepthwiseConv2D(kernel_size=5, padding=\"same\")(x)\n    conv_dilated = layers.DepthwiseConv2D(kernel_size=3, dilation_rate=2, padding=\"same\")(x)\n\n    # Feature Fusion via Concatenation\n    x1 = layers.Concatenate()([conv1x1, conv3x3, conv5x5, conv_dilated])\n\n    # Channel Shuffle for Better Feature Mixing\n    def channel_shuffle(x, groups):\n        batch, height, width, channels = tf.unstack(tf.shape(x))\n        x = tf.reshape(x, [-1, height, width, groups, channels // groups])\n        x = tf.transpose(x, [0, 1, 2, 4, 3])\n        x = tf.reshape(x, [-1, height, width, channels])\n        return x\n\n    x1 = layers.Lambda(lambda x: channel_shuffle(x, groups))(x1)\n\n    # Depthwise + Grouped Convolutions Hybrid\n    x1 = layers.DepthwiseConv2D(kernel_size=3, padding=\"same\")(x1)\n    x1 = layers.Conv2D(filters, kernel_size=1, padding=\"same\")(x1)\n\n    # Downsampling x1\n    x1 = layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x1)\n\n    # **Fix: Ensure x has the same number of channels as x1**\n    x = layers.Conv2D(filters, kernel_size=1, padding=\"same\")(x)\n    x = layers.DepthwiseConv2D(kernel_size=3, strides=strides, padding=\"same\")(x)\n\n    # Residual Connection\n    x = layers.Add()([x, x1])\n    x = layers.Activation(\"relu\")(x)\n    \n    return x\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\n## MSGCA\n'''def multi_kernel_groupwise_conv(x, filters, groups=8, strides=1, use_se=True):\n    # GPC for MSGDC\n    conv1x1 = layers.Conv2D(filters, kernel_size=1, groups=groups, strides=strides, padding=\"same\", use_bias=False)(x)\n    \n\n    # DDC (Multi-scale receptive fields) for MSGDC\n    conv3x3 = layers.DepthwiseConv2D(kernel_size=3, dilation_rate=1, strides=strides, padding=\"same\", use_bias=False)(x)\n    \n\n    # DWC (Multi-scale receptive fields) for MSGDC\n    conv5x5 = layers.DepthwiseConv2D(kernel_size=5, strides=strides, padding=\"same\", use_bias=False)(x)\n    \n\n    # Concatenation and 1x1 Fusion for MSHC\n    x1 = layers.Concatenate()([conv1x1, conv3x3, conv5x5])\n\n    def channel_shuffle(x, groups):\n        batch, height, width, channels = tf.unstack(tf.shape(x))\n        x = tf.reshape(x, [-1, height, width, groups, channels // groups])\n        x = tf.transpose(x, [0, 1, 2, 4, 3])\n        x = tf.reshape(x, [-1, height, width, channels])\n        return x\n\n    x1 = layers.Lambda(lambda x: channel_shuffle(x, groups))(x1)\n    \n    x1 = layers.Conv2D(filters, kernel_size=1, groups=groups, padding=\"same\", use_bias=False)(x1)\n    x1 = layers.BatchNormalization()(x1)\n\n    # CA layer\n\n    GMN = tf.reduce_min(inputs, axis=[1, 2])(x1)\n    GMP = tf.reduce_max(inputs, axis=[1, 2])(x1)\n    GAP = tf.reduce_mean(inputs, axis=[1, 2])(x1)\n    GSP = tf.reduce_suminputs, axis=[1, 2])(x1)\n\n    \n    channel_add = GMN + GAP + GMP + GSP\n\n    channel_sub = GMP - GAP - GMN\n    \n    channel_info = channel_add + channel_sub\n\n    se = layers.Dense(filters // 16, activation='relu', use_bias=False)(div_channel)\n    se = layers.Dense(filters, activation='sigmoid', use_bias=False)(se)\n\n    se = layers.Reshape((1, 1, filters))(se)\n    \n    self.global_scale = self.add_weight(shape=(1, 1, 1, 1), initializer=tf.keras.initializers.HeNormal(), trainable=True, name='global_scale')\n    se *= self.global_scale\n    se = layers.Activation('sigmoid')(se)\n    \n    \n    x1 = layers.Multiply()([x1, se])\n\n    \n    # Residual Connection\n    x = layers.Conv2D(filters=filters, kernel_size=1, strides=strides, padding='same', use_bias=False)(x)\n    \n\n    x = layers.Add()([x, x1])\n    x = layers.Activation('relu')(x)  # GELU activation for better convergence\n\n    return x\n'''\n\n\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\n\n\ndef channel_shuffle(tensor, groups: int):\n    \"\"\"Shuffle channels (ShuffleNet-style).\"\"\"\n    b, h, w, c = tf.unstack(tf.shape(tensor))\n    tensor = tf.reshape(tensor, [b, h, w, groups, c // groups])\n    tensor = tf.transpose(tensor, [0, 1, 2, 4, 3])\n    tensor = tf.reshape(tensor, [b, h, w, c])\n    return tensor\n\n\n# EMILA\nclass MultiKernelGroupWiseConv(layers.Layer):\n    \"\"\"\n    Multi-kernel / group-wise conv block with channel-shuffle,\n    global min/max/avg/sum attention, and residual connection.\n    \"\"\"\n\n    def __init__(self,\n                 filters: int,\n                 groups: int = 2,\n                 strides: int = 1,\n                 use_se: bool = True,\n                 reduction: int = 4,\n                 **kwargs):\n        super().__init__(**kwargs)\n        self.filters = filters\n        self.groups = groups\n        self.strides = strides\n        self.use_se = use_se\n        self.reduction = reduction\n\n        # ── convolutions ───────────────────────────────────────────────\n        # 1×1 grouped of MSGDC\n        self.conv1x1 = layers.Conv2D(filters, 1,\n                                     strides=strides,\n                                     padding=\"same\",\n                                    # use_bias=False,\n                                     groups=groups)\n        self.bn1x1 = layers.BatchNormalization()\n\n        # dw-3×3   of MSGDC\n        self.dw3 = layers.DepthwiseConv2D(3, strides=strides,\n                                          padding=\"same\",\n                                         # use_bias=False\n                                         )\n        self.bn_dw3 = layers.BatchNormalization()\n        #self.pw3 = layers.Conv2D(filters, 1, padding=\"same\", use_bias=False, groups=groups)\n        #self.bn_pw3 = layers.BatchNormalization()\n\n        # dw-5×5   of MSGDC\n        self.dw5 = layers.DepthwiseConv2D(5, strides=strides,\n                                          padding=\"same\",\n                                         # use_bias=False\n                                         )\n        self.bn_dw5 = layers.BatchNormalization()\n        #self.pw5 = layers.Conv2D(filters, 1, padding=\"same\", use_bias=False, groups=groups)\n        #self.bn_pw5 = layers.BatchNormalization()\n\n        # fusion after concat\n        self.fuse = layers.Conv2D(filters, 1,\n                                  padding=\"same\",\n                                 # use_bias=False, \n                                  groups=2\n                                  )\n        self.bn_fuse = layers.BatchNormalization()\n\n        \n        #if use_se:\n        self.fc1 = layers.Dense(filters // reduction,\n                                activation=\"relu\")\n        self.fc2 = layers.Dense(filters)\n        self.reshape = layers.Reshape((1, 1, filters))\n\n        # residual projection\n        self.proj = layers.Conv2D(filters, 1,\n                                  strides=strides,\n                                  padding=\"same\",\n                                 # use_bias=False\n                                 )\n        self.bn_proj = layers.BatchNormalization()\n\n        #self.global_scale = self.add_weight(shape=(1, 1, 1, 1), initializer=tf.keras.initializers.HeNormal(), trainable=True, name='global_scale')\n    \n\n        self.act = layers.Activation(\"relu\")\n\n    # global trainable scale requested by you\n    def build(self, input_shape):\n        self.global_scale = self.add_weight(\n            name=\"global_scale\",\n            shape=(1, 1, 1, 1),\n            initializer=tf.keras.initializers.HeNormal(),\n            trainable=True,\n        )\n        super().build(input_shape)\n\n    def call(self, x):\n        # ── branch 1: grouped 1×1 ──────────────────────────────────────\n        b1 = self.conv1x1(x)\n\n        # ── branch 2: dw-3×3 ──────────────────────────────────────────\n        b2 = self.dw3(x)\n        #b2 = self.bn_dw3(b2)\n        #b2 = self.pw3(b2)\n\n        # ── branch 3: dw-5×5 ──────────────────────────────────────────\n        b3 = self.dw5(x)\n        #b3 = self.bn_dw5(b3)\n        #b3 = self.pw5(b3)\n\n        # ── concat + shuffle + fuse ───────────────────────────────────\n        out = tf.concat([b1, b2, b3], axis=-1)\n        out = channel_shuffle(out, self.groups)\n        out = self.bn_fuse(self.fuse(out))\n\n        # ── CA  ────────────────\n        \n        g_min = tf.reduce_min(out, axis=[1, 2])\n        g_max = tf.reduce_max(out, axis=[1, 2])\n        g_avg = tf.reduce_mean(out, axis=[1, 2])\n        g_sum = tf.reduce_sum(out, axis=[1, 2])\n\n        channel_add = g_min + g_avg + g_max + g_sum \n        channel_sub = g_max - g_avg - g_min\n        channel_info = channel_add + channel_sub\n\n        se = self.fc1(channel_info)\n        se = self.fc2(se)\n        se = self.reshape(se)                  # (1,1,C)\n        # ← the three lines you explicitly asked for\n\n        \n        se *= self.global_scale\n        se = tf.nn.sigmoid(se)\n\n        out *= se\n\n        \n\n        #print('out shape:', out.shape)\n        #out = self.fuse(out) # GPC\n\n        # ── residual connection ───────────────────────────────────────\n        shortcut = self.bn_proj(self.proj(x))\n        out = self.act(shortcut + out)\n        return out\n\n\n\nimport tensorflow as tf\nfrom tensorflow.keras import layers\n\n### ERLA block\ndef RGSA(x, filters, strides=(1, 1), use_projection=False):\n    shortcut = x  # Save the original input for residual connection\n\n    # Multi-Kernel Groupwise Convolution (First Layer)\n    #x = MultiKernelGroupWiseConv(x, filters=filters, groups=16, strides=strides)\n\n    x = MultiKernelGroupWiseConv(filters=filters, groups=16, strides=strides)(x)\n\n    # Normalization and Activation\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n\n    # Second Depthwise and Pointwise Convolution\n    #x = MultiKernelGroupWiseConv(x, filters=filters, groups=16, strides=(1, 1))  # Strides=1 to avoid mismatch\n\n    x = MultiKernelGroupWiseConv(filters=filters, groups=16, strides=(1, 1))(x)\n    \n    x = layers.Conv2D(filters, kernel_size=(1, 1), padding=\"same\")(x)  # Pointwise conv for channel mixing\n    x = layers.BatchNormalization()(x)\n\n    # Adjust Shortcut if Needed (Ensure Matching Shape)\n    if strides != (1, 1) or use_projection:\n        shortcut = layers.Conv2D(filters, kernel_size=(1, 1), strides=strides, padding=\"same\")(shortcut)  # Downsampling shortcut\n        shortcut = layers.BatchNormalization()(shortcut)\n\n    # Residual Connection (Ensure Same Shape)\n    x = layers.Add()([x, shortcut])\n\n    # Final Activation\n    x = layers.Activation('relu')(x)\n\n    return x\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\n\nclass GlobalMinPooling2D(layers.Layer):\n    def __init__(self, **kwargs):\n        super(GlobalMinPooling2D, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        return tf.reduce_min(inputs, axis=[1, 2])\n\n    def compute_output_shape(self, input_shape):\n        return (input_shape[0], input_shape[-1])\n\n    def get_config(self):\n        config = super(GlobalMinPooling2D, self).get_config()\n        return config\n\n\n## EMCAM\nclass DeeperGlobalLocalAttentionLayer1(layers.Layer):\n    def __init__(self, units, activation='sigmoid', dropout_rate=0.2, groups=16, use_scale=True, **kwargs):\n        super(DeeperGlobalLocalAttentionLayer1, self).__init__(**kwargs)\n        self.units = units\n        self.activation = activation\n        self.dropout_rate = dropout_rate\n        self.use_scale = use_scale\n        self.groups = groups\n\n    def build(self, input_shape):\n        input1, input2 = input_shape\n        _, _, _, channels1 = input1\n        _, _, _, channels2 = input2\n        \n        self.alpha1 = self.add_weight(shape=(1, 1, 1, channels1), initializer='ones', trainable=True)\n        self.alpha2 = self.add_weight(shape=(1, 1, 1, channels2), initializer='ones', trainable=True)\n        \n        self.global_min_pooling = GlobalMinPooling2D()\n        self.global_avg_pooling = layers.GlobalAveragePooling2D()\n        self.global_max_pooling = layers.GlobalMaxPooling2D()\n        \n        self.global_attention = layers.Dense(units=self.units, activation=self.activation)\n        \n        self.local_conv1 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        self.local_conv2 = layers.Conv2D(filters=self.units, kernel_size=(1, 1), activation=self.activation)\n        \n        #self.min_pooling = MinPooling2D(pool_size = 1)\n        #self.min_pooling1 = MinPooling2D(pool_size = 1)\n        self.avg_pooling = layers.AveragePooling2D(pool_size = 1)\n        self.max_pooling = layers.MaxPooling2D(pool_size = 1)\n        \n        self.sub = layers.Subtract()\n        self.mod_scale1 = self.add_weight(shape=(1, 1, 1, 1), initializer='ones', trainable=True)\n        self.mod_scale2 = self.add_weight(shape=(1, 1, 1, 1), initializer='ones', trainable=True)\n        self.mod_scale3 = self.add_weight(shape=(1, 1, 1, 1), initializer='ones', trainable=True)\n        \n        self.msgdc_conv1x1 = layers.Conv2D(\n            self.units, 1, padding=\"same\", use_bias=False, groups=self.groups\n        )\n        self.msgdc_dw3 = layers.DepthwiseConv2D(\n            3, padding=\"same\", use_bias=False\n        )\n        self.msgdc_dw5 = layers.DepthwiseConv2D(\n            5, padding=\"same\", use_bias=False\n        )\n        self.msgdc_fuse = layers.Conv2D(\n            self.units, 1, padding=\"same\", use_bias=False\n        )\n        \n        if self.use_scale:\n            self.global_scale = self.add_weight(shape=(1, 1, 1, 1), initializer='ones', trainable=True, name='global_scale')\n            self.local_scale = self.add_weight(shape=(1, 1, 1, self.units), initializer='ones', trainable=True, name='local_scale')\n            \n            self.global_scale2 = self.add_weight(shape=(1, 1, 1, 1), initializer='ones', trainable=True, name='global_scale2')\n            self.local_scale2 = self.add_weight(shape=(1, 1, 1, self.units), initializer='ones', trainable=True, name='local_scale2')\n        \n        super(DeeperGlobalLocalAttentionLayer1, self).build(input_shape)\n\n    def MFIFA(self, x):\n            input_shape1 = tf.shape(x)\n            flattened_inputs1 = tf.reshape(x, [-1, input_shape1[-1]])  # Flatten along the last axis\n            dct_transformed1 = tf.signal.dct(flattened_inputs1, type=2, norm='ortho')\n            dct_transformed1 = tf.reshape(dct_transformed1, input_shape1)  # Reshape back to original dimensions\n            \n            High1 = self.global_max_pooling(dct_transformed1)   ## High 1\n            High1 = self.global_attention(High1)\n            High1 = tf.expand_dims(tf.expand_dims(High1, 1), 1)\n    \n            Low1 = self.global_avg_pooling(dct_transformed1)  ## Low 1\n            Low1 = self.global_attention(Low1)\n            Low1 = tf.expand_dims(tf.expand_dims(Low1, 1), 1)\n    \n            \n            Low2 = self.global_min_pooling(dct_transformed1)   ## Low 2\n            Low2 = self.global_attention(Low2)\n            Low2 = tf.expand_dims(tf.expand_dims(Low2, 1), 1)\n            \n            High2 = High1 - Low1\n            \n            High3 = dct_transformed1 - Low2\n    \n            High = High1 + High2 + High3\n            Low = Low1 + Low2\n            Mean = High - Low\n\n            #High = tf.expand_dims(tf.expand_dims(High, 1), 1)\n            #Low  = tf.expand_dims(tf.expand_dims(Low, 1), 1)\n            #Mean = tf.expand_dims(tf.expand_dims(Mean, 1), 1)\n    \n            High *= self.mod_scale1 # Modulation\n            Low *= self.mod_scale2 # Modulation\n            Mean *= self.mod_scale3 # Modulation\n            \n            return High, Low, Mean\n\n    \n    def _multi_kernel_groupwise_conv(self, x):\n        \"\"\"MSGDC block, *re-using* layers defined in build().\"\"\"\n        c1 = self.msgdc_conv1x1(x)\n        c3 = self.msgdc_dw3(x)\n        c5 = self.msgdc_dw5(x)\n\n        concat = tf.concat([c1, c3, c5], axis=-1)\n        return self.msgdc_fuse(concat)\n\n        \n\n    def call(self, inputs, training=None):\n        input1, input2 = inputs\n        \n        # MFIFA\n\n        High_1, Low_1, Mean_1 = self.MFIFA(input1) # for input modality 1\n        High_2, Low_2, Mean_2 = self.MFIFA(input2) # for input modality 2\n\n        \n        High = High_1 + High_2\n        Low = Low_1 + Low_2\n        Mean = Mean_1 + Mean_2\n        \n        attention = tf.sigmoid(High + Low + Mean)  # MFIFA Attention map generation\n        \n        \n        # Deeper Spatial Attention\n        \n        local_attention1 = self._multi_kernel_groupwise_conv(input1) #self.local_conv1(input1)\n        local_attention1_mean = tf.reduce_mean(local_attention1, axis=[1, 2], keepdims=True)\n        local_attention1_max = tf.reduce_max(local_attention1, axis=[1, 2], keepdims=True)\n        local_attention1 = local_attention1_max + local_attention1_mean\n\n        local_attention2 = self._multi_kernel_groupwise_conv(input2) #self.local_conv1(input1)\n        local_attention2_mean = tf.reduce_mean(local_attention2, axis=[1, 2], keepdims=True)\n        local_attention2_max = tf.reduce_max(local_attention2, axis=[1, 2], keepdims=True)\n        local_attention2 = local_attention2_max + local_attention2_mean\n        \n        \n        \n        local_attention1_1 = self._multi_kernel_groupwise_conv(local_attention1)\n        local_attention1_1_mean = tf.reduce_mean(local_attention1_1, axis=[1, 2], keepdims=True)\n        local_attention1_1_max = tf.reduce_max(local_attention1_1, axis=[1, 2], keepdims=True)\n        local_attention1 = local_attention1 + local_attention1_1_mean + local_attention1_1_max  + local_attention2 # Skip with Cross-modal Interactions\n\n        \n        \n        local_attention2_1 = self._multi_kernel_groupwise_conv(local_attention2)\n        local_attention2_1_mean = tf.reduce_mean(local_attention2_1, axis=[1, 2], keepdims=True)\n        local_attention2_1_max = tf.reduce_max(local_attention2_1, axis=[1, 2], keepdims=True)\n        local_attention2 = local_attention2 + local_attention2_1_mean + local_attention2_1_max  + local_attention1 # Skip with Cross-modal Interactions\n\n        \n        #local_attention2 = local_attention2_ + local_attention2__\n\n        # Scale Global and Spatial Attention\n    \n        \n        local_attention1 *= self.local_scale # Modulation\n        local_attention2 *= self.local_scale2 # Modulation\n\n        # Combine \n        attention1 = tf.sigmoid(local_attention1 + local_attention2) # EMSCA Attention map generation\n\n        attention *= self.global_scale # Modulation\n        attention1 *= self.local_scale # Modulation\n        \n        attention2 = tf.sigmoid(attention + attention1) # dUal domain Parallel Fusion Attention Map Generation via EMCAM\n        \n        \n        return attention2 \n\n    def get_config(self):\n        config = super(DeeperGlobalLocalAttentionLayer1, self).get_config()\n        config.update({'units': self.units, 'activation': self.activation, 'dropout_rate': self.dropout_rate,\n                       'use_scale': self.use_scale})\n        return config\n\n\n## EMCAM Attention Map Integration Into Input modalities\nclass DeeperAttentionLayer1(layers.Layer):\n    def __init__(self, units=64, use_scale=True, **kwargs):\n        super(DeeperAttentionLayer1, self).__init__(**kwargs)\n        self.units = units\n        self.use_scale = use_scale\n\n    def build(self, input_shape):\n        input1, input2 = input_shape\n        _, H, W, C1 = input1\n        _, H, W, C2 = input2\n        \n        self.alpha3 = self.add_weight(shape=(1, 1, 1, C1), initializer='ones', trainable=True, name='alpha3')\n        self.alpha4 = self.add_weight(shape=(1, 1, 1, C2), initializer='ones', trainable=True, name='alpha4')\n        self.add = layers.Add()\n        self.deeper_global_local_attention = DeeperGlobalLocalAttentionLayer1(units=self.units, activation='sigmoid', \n                                                                              dropout_rate=0.2,\n                                                                              use_scale=self.use_scale)\n        super(DeeperAttentionLayer1, self).build(input_shape)\n\n    def call(self, inputs, training=None):\n        input1, input2 = inputs\n        attention2 = self.deeper_global_local_attention(inputs, training=training)\n        attention_feature1 = input1 * attention2 * self.alpha3 # Attention Map Integration Into Input modality 1\n        attention_feature2 = input2 * attention2 * self.alpha4 # Attention Map Integration Into Input modality 2\n        \n        #attention_feature = self.add([attention_feature1, attention_feature2])\n        return attention_feature1, attention_feature2\n\n    def get_config(self):\n        config = super(DeeperAttentionLayer1, self).get_config()\n        config.update({'units': self.units, 'use_scale': self.use_scale})\n        return config\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## MSTL\ndef residual_GLC_branch1(inputs1, inputs2):\n    \n    x1 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs1)\n    #x1 = DeeperAttentionLayer1(units=64, use_scale=True)(x1) ## MFA ####\n    #x1 = AttentionBlock(64)(x1)\n    x1 = BatchNormalization()(x1)\n    x1 = tf.keras.layers.Activation('relu')(x1)\n    x1 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x1)\n    \n    x2 = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='same')(inputs2)\n    #x2 = DeeperAttentionLayer1(units=64, use_scale=True)(x2) ## MFA ####\n    #x2 = AttentionBlock(64)(x2)\n    x2 = BatchNormalization()(x2)\n    x2 = tf.keras.layers.Activation('relu')(x2)\n    x2 = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x2)\n    \n    ## ERLA\n    x1 = RGSA(x1, filters=64)\n    #\n    x2 = RGSA(x2, filters=64)\n    \n    \n    \n    \n    x1 = RGSA(x1, filters=64)\n    \n    x2 = RGSA(x2, filters=64)\n    \n    x1, x2 = DeeperAttentionLayer1(units=64, use_scale=True)([x1, x2])\n    \n    ## ERLA\n    x1 = RGSA(x1, filters=128, strides=(2, 2), use_projection=True)\n    \n    x2 = RGSA(x2, filters=128, strides=(2, 2), use_projection=True)\n    \n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True) \n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True) \n    \n    \n    \n    x1 = RGSA(x1, filters=128)\n    \n    x2 = RGSA(x2, filters=128)\n\n    \n    x1, x2 = DeeperAttentionLayer1(units=128, use_scale=True)([x1, x2])\n    \n    ## ERLA\n    x1 = RGSA(x1, filters=256, strides=(2, 2), use_projection=True)\n    \n    \n    x2 = RGSA(x2, filters=256, strides=(2, 2), use_projection=True)\n    \n\n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True) \n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True) \n    \n    \n    \n    x1 = RGSA(x1, filters=256)\n    \n    x2 = RGSA(x2, filters=256)\n    \n    x1, x2 = DeeperAttentionLayer1(units=256, use_scale=True)([x1, x2])\n    \n    \n    ## ERLA\n    x1 = RGSA(x1, filters=512, strides=(2, 2), use_projection=True)\n    \n    x2 = RGSA(x2, filters=512, strides=(2, 2), use_projection=True)\n\n    x1 = tf.keras.layers.Dropout(0.25)(x1, training = True) \n    x2 = tf.keras.layers.Dropout(0.25)(x2, training = True) \n    \n    \n    ## ERLA\n    x1 = RGSA(x1, filters=512)\n    x2 = RGSA(x2, filters=512)\n\n    x1, x2 = DeeperAttentionLayer1(units=512, use_scale=True)([x1, x2])\n    \n    \n    return x1, x2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#def build_resnet18(input_shape=(128, 128, 3), num_classes=2):\ninput_shape=(128, 128, 3)\ninputs1 = Input(shape=input_shape)\ninputs2 = Input(shape=input_shape)\n\nimport tensorflow.keras.layers as L\n\n#input_data = Input(shape=input_shape, name='input_data')\n# Initial convolutional layer\n\nx1, x2 = residual_GLC_branch1(inputs1, inputs2)\n#print('x:',x.shape)\n\n\ncon = tf.keras.layers.Concatenate(axis=-1)([x1, x2])\n\n#con = tf.keras.layers.Dropout(0.25)(con) \n\nx = GlobalAveragePooling2D()(con)\n#print('GlobalAveragePooling2D x:',x.shape)\n\n## TMTL\noutputs1 = Dense(5, activation='softmax')(x)\noutputs2 = Dense(7, activation='softmax')(x)\n\n# Create the model\nmodel = Model([inputs1, inputs2], [outputs1, outputs2])\n#return model\nprint(model.summary())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\ninitial_gamma = 0.5\nlearning_rate = 1e-2\noptimizer = Adam(learning_rate=0.0001)\n#opt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.9, epsilon=None, amsgrad=False)\n# Compile the model with the custom optimizer\nmodel.compile(optimizer=optimizer,\n              loss=['categorical_crossentropy', 'categorical_crossentropy'],\n              loss_weights=[initial_gamma, (1 -  initial_gamma)],\n              metrics=['accuracy', 'accuracy'])\n\n\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\ndef checkpoint_callback():\n\n    checkpoint_filepath = 'best1_model_cer_skin_lung.keras'\n\n    model_checkpoint_callback= ModelCheckpoint(filepath=checkpoint_filepath,\n                           save_weights_only=False,\n                           #frequency='epoch',\n                           monitor='val_loss',\n                           save_best_only=True,\n                            mode='min',\n                           verbose=1)\n\n    return model_checkpoint_callback\n\ndef early_stopping(patience):\n    es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', restore_best_weights=True, patience=80, verbose=1)\n    return es_callback\n\n\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n                              patience=70, verbose = 1, min_lr=0.00001)\n\ncheckpoint_callback = checkpoint_callback()\n\nearly_stopping = early_stopping(patience=100)\ncallbacks = [checkpoint_callback, early_stopping, reduce_lr]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fit the model with callbacks\nhistory = model.fit([X_train_s, X_train_h], [y_train_s, y_train_h],\n                    epochs=200,\n                    validation_data=([X_val_s, X_val_h1], [y_val_s, y_val_h1]), verbose=1,\n                    shuffle=True,\n                    callbacks=callbacks) # UpdateGammaCallback","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.evaluate([X_test_s, X_test_h1], [y_test_s, y_test_h1])","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}